from transformers import pipeline, AutoModelForSequenceClassification, BertJapaneseTokenizerfrom janome.tokenizer import Tokenizerfrom wordcloud import WordCloudimport os, collections, openpyxlimport matplotlib.pyplot as pltfont = '/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc'def extract_nouns(arr):    t = Tokenizer()    noun = []    #このfor文で引数に渡された配列を一つずつ取り出し（レビューを一つずつ取り出し）、変数reviewに代入する    for review in arr:        #このfor文で1つのレビューを形態素解析し、単語ごとに変数tokenに代入する。        for token in t.tokenize(review):            #自分で考えて記述            if token.part_of_speech.split(',')[0] == '名詞':                noun.append(token.surface)    return noundef display_nouns(arr, title):    #多次元配列nounsの宣言    nouns = []    for i in range(10):        #名詞を取得        noun = collections.Counter(arr).most_common()[i][0]        #名詞の出現回数        num = collections.Counter(arr).most_common()[i][1]        ratio = (num/len(arr)) * 100        #nounとratioを1つの配列にして、多次元配列nounsに追加で代入        nouns.append([noun, ratio])    make_graph(nouns, title)    def make_graph(nouns, title):    #配列の宣言    label = []    value = []        for dt in nouns:        label.append(dt[0])        value.append(dt[1])            #横向き用に破裂を逆順に並べる    label.reverse()    value.reverse()        #フォントと解像度の指定    plt.rcParams['font.family'] = 'Hiragino sans'    plt.figure(dpi=150)        # タイトル、軸の名前の指定    plt.title(title)    plt.xlabel('出現割合[%]')    plt.ylabel('出現名詞')    # データラベルの指定    for i in range(len(label)):    # 表示するデータラベルは、「［小数第3位までの数字］%」となるようにする    	plt.annotate(f'{value[i]:.3f}%', (value[i], i), va='center')            if title == 'Positive':        color = 'coral'    elif title == 'Negative':        color = 'navy'    else:        color = 'limegreen'    #横軸の最小値と最大値を指定    plt.xlim(0,4)    # 横向き棒グラフ    plt.barh(label, value, color=color)    # グラフをpngファイルで作業フォルダーに保存する    plt.savefig(title)    def make_excel():    wb = openpyxl.Workbook()    #最初のシートを指定する    sheet = wb.active    #シート名をサマリーに変更    sheet.title = 'サマリー'    filename = ['Positive', 'Negative', 'Neutral']    i = 0        for fname in filename:        img = openpyxl.drawing.image.Image(f'{fname}.png')        img.width /= 2        img.height /= 2        sheet.add_image(img, f'A{16*i+1}')        i += 1    #新しく「ワードクラウド」シートを作成する    wb.create_sheet('ワードクラウド')    #「ワードクラウド」シートを指定する    sheet = wb['ワードクラウド']    cloudname = ['pos_wc.png','neg_wc.png','neut_wc.png']    i = 0    for cname in cloudname:        img = openpyxl.drawing.image.Image(cname)        img.width /= 3        img.height /= 3        sheet.cell(15*i+1, 1).value = cname        #new_sheet.cell[f'A{15*i+1}'].value = fnameはエラーで実行できず。        sheet.add_image(img, f'B{15*i+1}')        i += 1    wb.save('report.xlsx')    with open('extract.txt', encoding='utf-8') as f:    contents = f.read()array = contents.splitlines()positive = []negative = []neutral = []if(os.path.isfile('arrays.txt')):    print('既に「arrays.txt」が存在したため、感情分析の処理をスキップします。')    with open('arrays.txt', encoding='utf-8') as f:        contents = f.read()            arrays = contents.splitlines()        positive = arrays[0].split('\t')    negative = arrays[1].split('\t')    neutral = arrays[2].split('\t')    else:    print('「extract.txt」に対して感情分析を行い、ポジティブ、ネガティブ、ニュートラルに分けます。（時間がかかります）')    model = AutoModelForSequenceClassification.from_pretrained('koheiduck/bert-japanese-finetuned-sentiment')    tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')    nlp = pipeline("sentiment-analysis",model=model,tokenizer=tokenizer)    for text in array:        res = nlp(text)        if res[0]['label'] == 'POSITIVE':            positive.append(text)        elif res[0]['label'] == 'NEGATIVE':            negative.append(text)        else:            neutral.append(text)    array_string = '\t'.join(positive) + '\n' + '\t'.join(negative) + '\n' + '\t'.join(neutral)    with open('arrays.txt', mode='w', encoding='utf-8') as f:        f.write(array_string)    print('感情ごとにレビューデータをまとめた「arrays.txt」を作成しました。')print('感情ごとにレビューのテキストデータから名詞を抽出します。')positive_nouns = extract_nouns(positive)negative_nouns = extract_nouns(negative)neutral_nouns = extract_nouns(neutral)print('感情ごとに使用上位10単語を抽出し、出現割合とともにグラフ化します。')display_nouns(positive_nouns, 'Positive')display_nouns(negative_nouns, 'Negative')display_nouns(neutral_nouns, 'Neutral')positive_wc = ' '.join(positive_nouns)negative_wc = ' '.join(negative_nouns)neutral_wc = ' '.join(neutral_nouns)pos_wc = WordCloud(font_path=font,                   background_color='coral',                   width=800,                   height=800,                   random_state=1                   ).generate(positive_wc)neg_wc = WordCloud(font_path=font,                   background_color='navy',                   width=800,                   height=800,                   random_state=1                   ).generate(negative_wc)neut_wc = WordCloud(font_path=font,                    background_color='limegreen',                    width=800,                    height=800,                    random_state=1                    ).generate(neutral_wc)pos_wc.to_file('pos_wc.png')neg_wc.to_file('neg_wc.png')neut_wc.to_file('neut_wc.png')print('グラフとワードクラウドをまとめたエクセルファイル「report.xlsx」を出力します。')make_excel()print('処理が完了しました。')